{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2c68b-b402-4348-bd37-a21c9db322fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245cb51-e155-48da-b637-82320f8e4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7db89-20c4-465b-b551-a8e05f794064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from mgi.data.sampled_datasets import load_sampled_datasets_metadata\n",
    "from mgi.data.datasets.wn18rrdecoded import WN18RRDecoded\n",
    "from mgi.data.datasets.fb15k237decoded import FB15K237Decoded\n",
    "from mgi.data.datasets.wd50k import WD50K\n",
    "from mgi.data.datasets.conceptnet import ConceptNet\n",
    "from mgi.data.datasets.yago import YAGO310\n",
    "from mgi.data.datasets.dataset_utils import get_ds_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e480d-0292-4a92-8071-3412f32d4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524f43d-0b6f-4d43-b006-0594442b9261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dataset_metadatas = load_sampled_datasets_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade47ae-9d6f-4276-8979-c65e6f4bbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_of_entities(dataset, subset):\n",
    "    return len(np.unique(getattr(dataset, subset).triples[:, [0, 2]].flatten()))\n",
    "\n",
    "\n",
    "def get_num_of_relations(dataset, subset):\n",
    "    return len(np.unique(getattr(dataset, subset).triples[:, 1].flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7feaa4-d0eb-4c29-af2e-40b82781b611",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d817e-b11b-42f6-85cf-aa111cb7e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "datasets = {\n",
    "    \"WN18RR\": WN18RRDecoded,\n",
    "    \"FB15K237\": FB15K237Decoded,\n",
    "    \"WD50K\": WD50K,\n",
    "    \"ConceptNet\": ConceptNet,\n",
    "    \"YAGO310\": YAGO310,\n",
    "}\n",
    "\n",
    "for name, dataset_cls in tqdm(list(datasets.items())):\n",
    "    dataset = dataset_cls.from_path()\n",
    "    data += [\n",
    "        {\n",
    "            \"dataset\": name,\n",
    "            \"train_triples\": dataset.dataset.training.num_triples,\n",
    "            \"val_triples\": dataset.dataset.validation.num_triples,\n",
    "            \"test_triples\": dataset.dataset.testing.num_triples,\n",
    "            \"train_entities\": get_num_of_entities(dataset, \"training\"),\n",
    "            \"val_entities\": get_num_of_entities(dataset, \"validation\"),\n",
    "            \"test_entities\": get_num_of_entities(dataset, \"testing\"),\n",
    "            \"train_relations\": get_num_of_relations(dataset, \"training\"),\n",
    "            \"val_relations\": get_num_of_relations(dataset, \"validation\"),\n",
    "            \"test_relations\": get_num_of_relations(dataset, \"testing\"),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.sort_values(\"dataset\")\n",
    "\n",
    "df[\"dataset\"] = pd.Categorical(\n",
    "    df[\"dataset\"], categories=[\"WN18RR\", \"FB15K237\", \"WD50K\", \"ConceptNet\", \"YAGO310\"], ordered=True\n",
    ")\n",
    "\n",
    "display(df)\n",
    "\n",
    "print(\n",
    "    df.style.format_index(axis=1, formatter=\"${}$\".format)\n",
    "    .hide(axis=0)\n",
    "    .to_latex(convert_css=True)\n",
    "    .replace(\"%\", \"\\%\")\n",
    "    .replace(\"±\", \"\\pm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9239222-c4cb-4f8b-93ab-bb1483a1651d",
   "metadata": {},
   "source": [
    "# Sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a2522-9a77-4511-bf92-a247adc9cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [121371, 59211, 44185]\n",
    "datasets = defaultdict(list)\n",
    "\n",
    "for name in ds_dataset_metadatas:\n",
    "    for seed in seeds:\n",
    "        datasets[name].append(get_ds_dataset(name, seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0536d-ff09-47fe-aba9-94bd70dfd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for name, list_datasets in tqdm(datasets.items()):\n",
    "    for ds_dataset in list_datasets:\n",
    "        data += [\n",
    "            {\n",
    "                **ds_dataset_metadatas[name].sampling_config,\n",
    "                \"train_triples\": ds_dataset.dataset.training.num_triples,\n",
    "                \"val_triples\": ds_dataset.dataset.validation.num_triples,\n",
    "                \"test_triples\": ds_dataset.dataset.testing.num_triples,\n",
    "                \"train_entities\": get_num_of_entities(ds_dataset, \"training\"),\n",
    "                \"val_entities\": get_num_of_entities(ds_dataset, \"validation\"),\n",
    "                \"test_entities\": get_num_of_entities(ds_dataset, \"testing\"),\n",
    "                \"train_relations\": get_num_of_relations(ds_dataset, \"training\"),\n",
    "                \"val_relations\": get_num_of_relations(ds_dataset, \"validation\"),\n",
    "                \"test_relations\": get_num_of_relations(ds_dataset, \"testing\"),\n",
    "            }\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea3e87-d682-45d7-8b38-22dfd9313cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_empty_rows_on_dataset_change(df):\n",
    "    empty_row = pd.DataFrame(columns=df.columns)\n",
    "    df_list = []\n",
    "    prev_dataset = None\n",
    "    for index, row in df.iterrows():\n",
    "        current_dataset = row[\"dataset\"]\n",
    "        if current_dataset.item() != prev_dataset:\n",
    "            df_list.append(pd.Series([current_dataset.item()] * len(df.columns), index=df.columns))\n",
    "        df_list.append(row)\n",
    "        prev_dataset = current_dataset.item()\n",
    "\n",
    "    result_df = pd.DataFrame(df_list)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336de1f3-c625-4e0d-b827-f26ca0397197",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.float_format\", \"{:.1f}\".format):\n",
    "    grouped = df.groupby([\"dataset\", \"sampling\", \"p\"]).agg([\"mean\", \"std\"])\n",
    "\n",
    "to_display = grouped.reset_index()\n",
    "to_display = to_display[[\"dataset\", \"sampling\", \"p\"]].copy()\n",
    "\n",
    "for col in grouped.columns.levels[0]:\n",
    "    decimal_places = 0\n",
    "    to_display[col] = (\n",
    "        (grouped[[(col, \"mean\"), (col, \"std\")]])\n",
    "        .apply(lambda x: f\"{x[0]:.{decimal_places}f}({x[1]:.{decimal_places}f})\", axis=1)\n",
    "        .tolist()\n",
    "    )\n",
    "to_display[\"dataset\"] = pd.Categorical(\n",
    "    to_display[\"dataset\"], categories=[\"WN18RR\", \"FB15K237\", \"WD50K\"], ordered=True\n",
    ")\n",
    "to_display[\"sampling\"] = pd.Categorical(\n",
    "    to_display[\"sampling\"], categories=[\"triple\", \"node\", \"relation\"], ordered=True\n",
    ")\n",
    "to_display = to_display.sort_values([\"dataset\", \"sampling\"])\n",
    "to_display = add_empty_rows_on_dataset_change(to_display)\n",
    "to_display = to_display.drop(columns=[\"dataset\"])\n",
    "display(to_display)\n",
    "print(\n",
    "    to_display.style.format(precision=1)\n",
    "    .format_index(axis=1, formatter=\"${}$\".format)\n",
    "    .hide(axis=0)\n",
    "    .to_latex(convert_css=True)\n",
    "    .replace(\"%\", \"\\%\")\n",
    "    .replace(\"±\", \"\\pm\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "22-multiple-graph-inference",
   "language": "python",
   "name": "22-multiple-graph-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
